{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74a7655-57c0-4cc9-b95c-e52c99fdc516",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4156ac67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import multiprocessing\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from optuna.pruners import MedianPruner\n",
    "import pickle\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import time\n",
    "from optuna.samplers import RandomSampler\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6418d6-86f0-441f-b34e-3c66807c169c",
   "metadata": {},
   "source": [
    "# Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e8849905-495a-4575-8883-e78de3ccc82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataset 1\n",
    "import gc\n",
    "def deref_all_refs(group, ref_container):\n",
    "    return [group[ref[0]][:] for ref in ref_container]\n",
    "\n",
    "def load_combined_data():\n",
    "    \"\"\"\n",
    "    Reads 'combinedEpochs_v2.mat' (HDF5) and concatenates trials across subjects.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    rotation_dataset_all_subjects : np.ndarray [sequence length, channels, num trials]\n",
    "    labels_all_subjects           : np.ndarray [1, num trials]\n",
    "    magnitudes_all_subjects       : np.ndarray [1, num trials]\n",
    "    \"\"\"\n",
    "\n",
    "#with h5py.File('eegEpochs_16subs_chanInterp_control.mat', 'r') as control_file, \\\n",
    "    with h5py.File('combinedEpochs_v2.mat', 'r') as bci_file:\n",
    "    \n",
    "        #control_group = control_file['eegEpochs']\n",
    "        bci_group = bci_file['combinedEpochs']\n",
    "    \n",
    "        #control_data_refs = deref_all_refs(control_group, control_group['rotation_data'])\n",
    "        bci_data_refs = deref_all_refs(bci_group, bci_group['rotation_data'])\n",
    "        #control_label_refs = deref_all_refs(control_group, control_group['label'])\n",
    "        bci_label_refs = deref_all_refs(bci_group, bci_group['label'])\n",
    "        #control_magnitude_refs = deref_all_refs(control_group, control_group['magnitude'])\n",
    "        bci_magnitude_refs = deref_all_refs(bci_group, bci_group['magnitude'])\n",
    "    \n",
    "        # Combine references\n",
    "        #all_data_refs = control_data_refs + bci_data_refs\n",
    "        #all_label_refs = control_label_refs + bci_label_refs\n",
    "        #all_magnitude_refs = control_magnitude_refs + bci_magnitude_refs\n",
    "        all_data_refs = bci_data_refs\n",
    "        all_label_refs = bci_label_refs\n",
    "        all_magnitude_refs = bci_magnitude_refs\n",
    "    \n",
    "        print('number of subjects:', len(all_data_refs))\n",
    "        print('checking shape of one subject:', all_data_refs[0].shape)\n",
    "    \n",
    "        # Cast to float32 to reduce memory\n",
    "        rotation_dataset = [ref[:].astype(np.float32) for ref in all_data_refs]\n",
    "        labels = [ref[:].astype(np.uint8) for ref in all_label_refs]\n",
    "        magnitudes = [ref[:].astype(np.uint8) for ref in all_magnitude_refs]\n",
    "    \n",
    "        # Clean up refs\n",
    "        #del control_data_refs, bci_data_refs, control_label_refs, bci_label_refs\n",
    "        #del control_magnitude_refs, bci_magnitude_refs, all_data_refs, all_label_refs, all_magnitude_refs\n",
    "        del bci_data_refs, bci_label_refs\n",
    "        del bci_magnitude_refs, all_data_refs, all_label_refs, all_magnitude_refs\n",
    "        gc.collect()\n",
    "    \n",
    "        # Concatenate\n",
    "        rotation_dataset_all_subjects = np.concatenate(rotation_dataset, axis=0)\n",
    "        labels_all_subjects = np.concatenate(labels, axis=1)\n",
    "        magnitudes_all_subjects = np.concatenate(magnitudes, axis=1)\n",
    "    \n",
    "        print('rotation shape:', rotation_dataset_all_subjects.shape)\n",
    "        print('labels shape:', labels_all_subjects.shape)\n",
    "        print('magnitudes shape:', magnitudes_all_subjects.shape)\n",
    "    \n",
    "        return rotation_dataset_all_subjects, labels_all_subjects, magnitudes_all_subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4d82e61c-45bc-48a8-ab92-9aff8f4cd313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataset 2\n",
    "\n",
    "import gc \n",
    "def deref_all_refs(group, ref_container):\n",
    "    return [group[ref[0]][:] for ref in ref_container]\n",
    "\n",
    "def load_neuromod_data():\n",
    "    \"\"\"\n",
    "    Reads 'discrete_errp.mat' (HDF5) and concatenates trials across subjects.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    rotation_dataset_all_subjects : np.ndarray [sequence length, channels, num trials]\n",
    "    labels_all_subjects           : np.ndarray [1, num trials]\n",
    "    magnitudes_all_subjects       : np.ndarray [1, num trials]\n",
    "    \"\"\"\n",
    "    \n",
    "    with h5py.File('discrete_errp.mat', 'r') as discrete_file:\n",
    "        #h5py.File('continuous_errp.mat', 'r') as continous_file, \\\n",
    "        \n",
    "        #continuous_group = continous_file['continuous_errp']\n",
    "        discrete_group = discrete_file['discrete_errp']\n",
    "    \n",
    "        #continuous_data_list = deref_all_refs(continuous_group, continuous_group['data'])\n",
    "        discrete_data_list = deref_all_refs(discrete_group, discrete_group['data'])\n",
    "        #continuous_label_list = deref_all_refs(continuous_group, continuous_group['label'])\n",
    "        discrete_label_list = deref_all_refs(discrete_group, discrete_group['label'])\n",
    "    \n",
    "        # Combine\n",
    "        #all_data = continuous_data_list + discrete_data_list\n",
    "        #all_labels = continuous_label_list + discrete_label_list\n",
    "        all_data = discrete_data_list\n",
    "        all_labels = discrete_label_list\n",
    "        neuromod_dataset = [x.astype(np.float32) for x in all_data]\n",
    "        labels = [x.astype(np.uint8) for x in all_labels]\n",
    "    \n",
    "        del all_data, all_labels\n",
    "        gc.collect()\n",
    "    \n",
    "        neuromod_dataset_all_subjects = np.concatenate(neuromod_dataset, axis=0)\n",
    "        labels_all_subjects = np.concatenate(labels, axis=1)\n",
    "    \n",
    "        return neuromod_dataset_all_subjects, labels_all_subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "64f70861",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Grand average plotting of error and correct trials\n",
    "\n",
    "def GA_plotting(data, labels, channel):\n",
    "    time_stamps = np.arange(-0.5, 1, 1/512)\n",
    "    error_matrix = data[:,channel,labels.flatten() == 1]\n",
    "    correct_matrix = data[:,channel,labels.flatten()==0]\n",
    "    plt.plot(time_stamps, np.mean(error_matrix, axis=1), label='Error Trials')\n",
    "    plt.plot(time_stamps, np.mean(correct_matrix, axis=1), label='Correct Trials')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    error_mean = np.mean(error_matrix, axis=1)\n",
    "    correct_mean = np.mean(correct_matrix, axis=1)\n",
    "    return error_mean, correct_mean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf169a2e-c75e-4fe4-a0a8-789236a99be9",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8ea97cb5",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "#Basic preprocessing: sequence rejection via amplitude thresholding\n",
    "\n",
    "def sequence_rejection(data, labels, magnitudes, task_labels, threshold):\n",
    "    \"\"\"\n",
    "    data         : np.ndarray [sequence length, channels, num trials]\n",
    "    labels       : np.ndarray [num trials]\n",
    "    magnitudes   : np.ndarray [num trials]\n",
    "    task_labels  : np.ndarray [num trials]\n",
    "    threshold    : float \n",
    "\n",
    "    Returns cleaned versions of all inputs.\n",
    "    \"\"\"\n",
    "    \n",
    "    trials = data.shape[2]\n",
    "    keep_mask = np.ones(trials, dtype=bool)\n",
    "    for trial_id in range(trials):\n",
    "        if np.any(data[:,:, trial_id] > threshold):\n",
    "            keep_mask[trial_id] = False\n",
    "    cleaned_data = data[:,:,keep_mask]\n",
    "    cleaned_labels = labels[keep_mask]\n",
    "    cleaned_magnitudes = magnitudes[keep_mask]\n",
    "    cleaned_task_labels = task_labels[keep_mask]\n",
    "    return cleaned_data, cleaned_labels, cleaned_magnitudes, cleaned_task_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f5789060-f746-4799-8742-3b87ffd668be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic preprocessing: Spatial filtering to increase spatial resolution\n",
    "def spatial_filter(data):\n",
    "    \"\"\"\n",
    "    data : np.ndarray [sequence length, channels, num trials]\n",
    "    Returns same shape, each sample channel demeaned across channels.\n",
    "    \"\"\"\n",
    "    return data - np.mean(data, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd3789f-c1c7-4e65-9161-6b2117c86bbd",
   "metadata": {},
   "source": [
    "# Dataset creation and splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "098b5c32",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "#PyTorch Dataset for single trial ErrP sequences\n",
    "\n",
    "class ErrPDataset(Dataset):\n",
    "    def __init__(self, sequences, labels, magnitudes, task_labels):\n",
    "        \"\"\"\n",
    "        Args\n",
    "        ----\n",
    "        sequences  : np.ndarray [num trials, seq_len, num_features]\n",
    "        labels     : np.ndarray,  [num_trials]\n",
    "                     Binary (0/1) sequence-level labels.\n",
    "        magnitudes : np.ndarray [num_trials]\n",
    "        task_labels: np.ndarray [num_trials]\n",
    "        \"\"\"\n",
    "        self.sequences = sequences  # [num trials, seq_len, num_features]\n",
    "        self.labels = labels        # [num_trials], sequence level classification\n",
    "        self.magnitudes = magnitudes # [num_trials]\n",
    "        self.task_labels = task_labels  # [num_trials]\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    def __getitem__(self, idx):\n",
    "        # sequences[idx] is of size [seq_len, num_features]\n",
    "        return {'features': torch.tensor(self.sequences[idx], dtype=torch.float), \\\n",
    "                'labels': torch.tensor(self.labels[idx], dtype=torch.long), \\\n",
    "               'magnitudes': torch.tensor(self.magnitudes[idx], dtype=torch.long), \\\n",
    "               'task_labels': torch.tensor(self.task_labels[idx], dtype=torch.long)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69ee93a5",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# collate_fn to turn a list of sample dicts into batch tensors\n",
    "\n",
    "def collate_fn(batch):\n",
    "    sequences = [x['features'] for x in batch]\n",
    "    labels = [x['labels'] for x in batch]\n",
    "    magnitudes = [x['magnitudes'] for x in batch]\n",
    "    task_labels = [x['task_labels'] for x in batch]\n",
    "    return torch.stack(sequences), torch.stack(labels), torch.stack(magnitudes), torch.stack(task_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb269a56",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "#Function for dataset split (train / val / test)\n",
    "\n",
    "def Dataset_splitting(tensor_data, train_ratio, val_ratio, test_ratio):\n",
    "     \"\"\"\n",
    "    Args\n",
    "    ----\n",
    "    tensor_data : Dataset object (ErrPDataset)\n",
    "    train_ratio : float in (0,1)\n",
    "    val_ratio   : float in (0,1)\n",
    "    test_ratio  : float in (0,1)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    train_set, test_set, val_set : lists of dicts\n",
    "    \"\"\"\n",
    "    \n",
    "    indices = np.arange(len(tensor_data))\n",
    "    # deterministic (no shuffle) split; shuffle externally\n",
    "    train_size = int(len(indices) * train_ratio)\n",
    "    val_size = int(len(indices) * val_ratio)\n",
    "    train_indices = indices[:train_size]\n",
    "    val_indices = indices[train_size:train_size+val_size]\n",
    "    test_indices = indices[train_size+val_size:]\n",
    "    train_set = [tensor_data[x] for x in train_indices]\n",
    "    val_set = [tensor_data[x] for x in val_indices]\n",
    "    test_set = [tensor_data[x] for x in test_indices]\n",
    "    return train_set, test_set, val_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a076cda7-3c0e-49e6-8388-548ae81f14aa",
   "metadata": {},
   "source": [
    "# Feature-wise normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60eb3b6f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "#Function for Per-channel, per-time-step z-score normalization\n",
    "\n",
    "def data_normalization(train_data, test_data, val_data): \n",
    "     \"\"\"\n",
    "    Args\n",
    "    train_data / test_data / val_data : list[dict]\n",
    "    Returns\n",
    "    The same three lists (modified in place).\n",
    "    \"\"\"\n",
    "    \n",
    "    temp_train_data = [x['features'] for x in train_data]\n",
    "    temp_train_data = torch.stack(temp_train_data)\n",
    "    num_samples, seq_len, num_features = temp_train_data.shape\n",
    "    #obtain mean and std from the train set, and apply it to val and test set\n",
    "    for chan_id in range (num_features):\n",
    "        channel_data = temp_train_data[:,:,chan_id]\n",
    "        mean = torch.mean(channel_data, dim=0, keepdim=True)\n",
    "        std = torch.std(channel_data, dim=0, keepdim=True)\n",
    "        # Apply to train set\n",
    "        for x in train_data:\n",
    "            x['features'][:, chan_id] = (x['features'][:, chan_id] - mean.squeeze(0)) / (std.squeeze(0) + 1e-6)\n",
    "        # Apply to val set\n",
    "        for x in val_data:\n",
    "            x['features'][:, chan_id] = (x['features'][:, chan_id] - mean.squeeze(0)) / (std.squeeze(0) + 1e-6)\n",
    "        # Apply to test set\n",
    "        for x in test_data:\n",
    "            x['features'][:, chan_id] = (x['features'][:, chan_id] - mean.squeeze(0)) / (std.squeeze(0) + 1e-6)\n",
    "    \n",
    "    return train_data, test_data, val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec0b470b-c7b5-4057-9154-8a843fde1664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function  for global (sequence-wide) z-score normalisation performed per channel\n",
    "\n",
    "def data_normalization_v2(train_data, test_data, val_data): \n",
    "    \"\"\"\n",
    "    Args\n",
    "    ----\n",
    "    train_data / test_data / val_data : list[dict]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    The same three lists (modified in place).\n",
    "    \"\"\"\n",
    "    \n",
    "    temp_train_data = [x['features'] for x in train_data]\n",
    "    temp_train_data = torch.stack(temp_train_data)\n",
    "    num_samples, seq_len, num_features = temp_train_data.shape\n",
    "    #obtain mean and std from the train set, and apply it to val and test set\n",
    "    for chan_id in range (num_features):\n",
    "        channel_data = temp_train_data[:,:,chan_id]\n",
    "        mean = torch.mean(channel_data, dim=[0,1], keepdim=True)\n",
    "        std = torch.std(channel_data, dim=[0,1], keepdim=True)\n",
    "        # Apply to train set\n",
    "        for x in train_data:\n",
    "            x['features'][:, chan_id] = (x['features'][:, chan_id] - mean.squeeze(0)) / (std.squeeze(0) + 1e-6)\n",
    "        # Apply to val set\n",
    "        for x in val_data:\n",
    "            x['features'][:, chan_id] = (x['features'][:, chan_id] - mean.squeeze(0)) / (std.squeeze(0) + 1e-6)\n",
    "        # Apply to test set\n",
    "        for x in test_data:\n",
    "            x['features'][:, chan_id] = (x['features'][:, chan_id] - mean.squeeze(0)) / (std.squeeze(0) + 1e-6)\n",
    "\n",
    "    \n",
    "    return train_data, test_data, val_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2429881d-eb1a-4ebb-a990-21af2519c35b",
   "metadata": {},
   "source": [
    "# RNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7063154",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "#Vanilla RNN\n",
    "\n",
    "class ErrPDetectionRNNModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Plain GRU → Dropout → Linear classifier.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout_rate, output_size):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    #Input size: batch_size, sequence_length, features\n",
    "    #Output size: batch_size\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        output, _ = self.gru(x)\n",
    "        output = self.dropout(output)\n",
    "        last_time_step = output[:, -1, :] #batch size, sequence length, hidden_size\n",
    "        output = self.fc(last_time_step)\n",
    "        #logits, need to be passed through sigmoid before thresholding\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce2475f4-5332-46e7-ada0-6c0e53db27ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRU + attention mechanisms\n",
    "\n",
    "class ErrPDetectionRNNModel_with_att(nn.Module):\n",
    "    \"\"\"\n",
    "    GRU backbone with a simple additive attention pooled across time.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout_rate, output_size):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.attention_layer = nn.Linear(hidden_size, 1)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    #Input size: batch_size, sequence_length, features\n",
    "    #Output size: batch_size\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        output, _ = self.gru(x)\n",
    "        output = self.dropout(output)\n",
    "        attn_scores = self.attention_layer(output)\n",
    "        attn_weights = F.softmax(attn_scores, dim=1)\n",
    "        context = torch.sum(attn_weights * output, dim=1)\n",
    "        output = self.fc(context)\n",
    "        #logits, need to be passed through sigmoid before thresholding\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c1965a7-1b17-44c0-a1ce-87ac95c41041",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN + GRU + attention mechanisms\n",
    "\n",
    "class ErrPDetection_CNN_GRU_Attn(nn.Module):\n",
    "    \"\"\"\n",
    "    1-D convolutional frontend (spatial-temporal filtering) + GRU +\n",
    "    self-attention pooling.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_size, cnn_out_channels, cnn_kernel_size,\n",
    "                 hidden_size, num_layers, dropout_rate, output_size):\n",
    "      \n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn = nn.Conv1d(\n",
    "            in_channels=input_size,\n",
    "            out_channels=cnn_out_channels,\n",
    "            kernel_size=cnn_kernel_size,\n",
    "            padding=cnn_kernel_size // 2  # 'same' padding\n",
    "        )\n",
    "        self.bn = nn.BatchNorm1d(cnn_out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # GRU input size = cnn_out_channels (features per timepoint)\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=cnn_out_channels,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        # Attention layer\n",
    "        self.attention_layer = nn.Linear(hidden_size, 1)\n",
    "\n",
    "        # Final classifier\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # permute needed to match input size: x: [batch, channels, time]\n",
    "        x = x.permute(0, 2, 1) \n",
    "        x = self.cnn(x)                     # [batch, cnn_out_channels, time]\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        x = x.permute(0, 2, 1)             # [batch, time, cnn_out_channels] → GRU input\n",
    "\n",
    "        gru_out, _ = self.gru(x)           # [batch, time, hidden_size]\n",
    "        gru_out = self.dropout(gru_out)\n",
    "\n",
    "        attn_scores = self.attention_layer(gru_out)  # [batch, time, 1]\n",
    "        attn_weights = F.softmax(attn_scores, dim=1)\n",
    "        context = torch.sum(attn_weights * gru_out, dim=1)  # [batch, hidden_size]\n",
    "\n",
    "        output = self.fc(context)          # [batch, output_size]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70808113-493d-424d-8e37-b698bc59457e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bidirectional GRU + attention mechanisms\n",
    "\n",
    "class ErrPDetectionRNNModel_with_att_bidir(nn.Module):\n",
    "    \"\"\"\n",
    "    Bidirectional GRU + temporal attention.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout_rate, output_size):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True \n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        # Attention layer takes 2 * hidden_size \n",
    "        self.attention_layer = nn.Linear(2 * hidden_size, 1)\n",
    "        \n",
    "        # Final classifier layer also takes 2 * hidden_size\n",
    "        self.fc = nn.Linear(2 * hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        gru_output, _ = self.gru(x)  \n",
    "        gru_output = self.dropout(gru_output)\n",
    "\n",
    "        # Attention weights over time steps\n",
    "        attn_scores = self.attention_layer(gru_output)  # [batch_size, seq_len, 1]\n",
    "        attn_weights = F.softmax(attn_scores, dim=1)    \n",
    "\n",
    "        context = torch.sum(attn_weights * gru_output, dim=1)  # [batch_size, 2 * hidden_size]\n",
    "\n",
    "        # Final classification\n",
    "        output = self.fc(context)  # [batch_size, output_size]\n",
    "        return output  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1e6041-9a5d-4ec1-8907-3d0fd5cf59a3",
   "metadata": {},
   "source": [
    "# Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "384a7b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binary-class cross entropy loss\n",
    "def cross_entropy_loss(predictions, labels, class_weights):\n",
    "    \"\"\"\n",
    "    Args\n",
    "    ----\n",
    "    predictions : raw logits [batch_size]\n",
    "    labels      : 0 / 1 [batch_size]\n",
    "    class_weights : 1-D FloatTensor for pos_weight\n",
    "    \"\"\"\n",
    "    loss_fn = nn.BCEWithLogitsLoss(pos_weight=class_weights) if class_weights is not None else nn.BCEWithLogitsLoss()\n",
    "    loss = loss_fn(predictions,labels.float())\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fe8a2141",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Returns TPR, TNR, Accuracy given hard predictions\n",
    "\n",
    "def evaluation(predictions, labels): \n",
    "    \"\"\"\n",
    "    predictions / labels : 1-D tensors of equal length.\n",
    "    \"\"\"\n",
    "    #TPR\n",
    "    TP = torch.logical_and(predictions==1, labels==1)\n",
    "    TPR = TP.sum() / ((labels==1).sum() + 1e-6)\n",
    "    #TNR\n",
    "    TN = torch.logical_and(predictions==0, labels==0)\n",
    "    TNR = TN.sum() / ((labels==0).sum() + 1e-6)\n",
    "    #Accuracy\n",
    "    accuracy = (TP.sum() + TN.sum()) / len(labels)\n",
    "    return TPR, TNR, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5cb62022",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "#Grid-search 0 → 1 step 0.01 for the best TPR×TNR threshold\n",
    "\n",
    "def threshold_tuning(all_probs_val, all_labels_val):\n",
    "    \"\"\"\n",
    "    all_probs_val  : tensor of sigmoid probabilities\n",
    "    all_labels_val : labels of equal length\n",
    "    \"\"\"\n",
    "    thresholds = [round(x * 0.01, 2) for x in range(101)]\n",
    "    best_performance = 0.0\n",
    "    best_threshold = thresholds[0]\n",
    "    for thres in thresholds:\n",
    "        predictions = all_probs_val > thres\n",
    "        TPR, TNR, accuracy = evaluation(predictions, all_labels_val)\n",
    "        perf = TPR * TNR\n",
    "        if perf > best_performance:\n",
    "            best_performance = perf\n",
    "            best_threshold = thres\n",
    "    return best_threshold, best_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f1b3f6-81b1-4541-bbb6-3044501fbec5",
   "metadata": {},
   "source": [
    "# Optuna hyper-parameter search (objective function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00560159",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Objective function of Optuna\n",
    "\n",
    "def objective(trial, number_of_features, train_loader, val_loader, device, folder_name):\n",
    "    \"\"\"\n",
    "    Optuna objective:\n",
    "      - Tune HPs\n",
    "      - instantiates model / optimiser / scheduler\n",
    "      - trains with early-stopping\n",
    "      - saves the best model checkpoint\n",
    "      - returns best validation score (TPR×TNR)\n",
    "    \"\"\"\n",
    "    \n",
    "    model_params = {}\n",
    "    \n",
    "    # Hyper-parameter space \n",
    "    tuning_params = {\n",
    "                    'hidden_size': trial.suggest_categorical('hidden_size', [200, 300, 400, 500]),\n",
    "                     'dropout_rate': trial.suggest_float('dropout_rate',0.1, 0.5),\n",
    "                     #'num_layers': trial.suggest_int('num_layers', 1, 5),\n",
    "                    'num_layers': trial.suggest_int('num_layers', 1, 5),\n",
    "                     'learning_rate': trial.suggest_loguniform('lr', 1e-5, 5e-4),\n",
    "                     'l2_lambda': trial.suggest_loguniform('l2_lambda', 1e-6, 1e-5),\n",
    "                     'epochs': 100,\n",
    "                     'optimizer': trial.suggest_categorical('optimizer',['Adam', 'RMSProp']),\n",
    "                     'learning_rate_scheduler': True,\n",
    "                     'patience': 5,\n",
    "                     'batch_size': 32,\n",
    "                     'class_weight_error': trial.suggest_float('class_weight_error', 0.5, 2.0)}\n",
    "\n",
    "    print(f\"\\n[OPTUNA] Starting trial {trial.number}\")\n",
    "    print(f\"[OPTUNA] Hyperparameters: {tuning_params}\")\n",
    "\n",
    "    # Model instantiation \n",
    "    model_params['num_layers'] = tuning_params['num_layers']\n",
    "    model_params['dropout_rate'] = tuning_params['dropout_rate']\n",
    "    model_params['hidden_size'] = tuning_params['hidden_size']\n",
    "    model_params['output_size'] = 1\n",
    "\n",
    "    #CNN parameters\n",
    "    model_params['input_size'] = number_of_features\n",
    "    #number of filters\n",
    "    #model_params['cnn_out_channels'] = 32\n",
    "    #kernel size, fixed for now, set to 100ms\n",
    "    #model_params['cnn_kernel_size'] = 50\n",
    "\n",
    "    #pass the parameters to device\n",
    "    model = ErrPDetectionRNNModel_with_att(**model_params).to(device)\n",
    "    #model = ErrPDetectionRNNModel(**model_params).to(device)\n",
    "\n",
    "    # Optimiser & LR scheduler\n",
    "    if tuning_params['optimizer'] == 'Adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=tuning_params['learning_rate'], weight_decay=tuning_params['l2_lambda'])\n",
    "    elif tuning_params['optimizer'] == 'RMSProp':\n",
    "        optimizer = optim.RMSprop(model.parameters(), lr=tuning_params['learning_rate'], weight_decay=tuning_params['l2_lambda'])\n",
    "\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=5, verbose=True, min_lr=1e-6)\n",
    "\n",
    "    #Storing epoch-wise performance for early stopping\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    no_improve_epochs = 0\n",
    "    best_perf = 0.0\n",
    "    best_tpr = 0.0\n",
    "    best_tnr = 0.0\n",
    "    best_acc = 0.0\n",
    "    best_threshold = 0.0\n",
    "    best_model = None\n",
    "    best_epoch = None\n",
    "    \n",
    "    #Enable multi-GPU\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "\n",
    "    print('training')\n",
    "    #Training loop \n",
    "    #iterations through epochs\n",
    "    for epoch in range (tuning_params['epochs']):\n",
    "        print('epoch number ' + str(epoch+1))\n",
    "        epoch_start_time = time.time()\n",
    "        #train\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        print('training loop, size of tensor: ' + str(len(train_loader)))\n",
    "        for i, (sequences, labels, magnitudes, task_labels) in enumerate(train_loader): #batch -> one update in weights\n",
    "            sequences,labels, magnitudes, task_labels = sequences.to(device), labels.to(device), magnitudes.to(device), task_labels.to(device)\n",
    "            #reset gradient\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(sequences)\n",
    "            #output size of 1\n",
    "            probabilities = torch.sigmoid(outputs)\n",
    "            #Loss computation\n",
    "            weight_tensor = torch.tensor([tuning_params['class_weight_error']], device=device)\n",
    "            loss = cross_entropy_loss(outputs, labels, class_weights=weight_tensor)\n",
    "            #backpropagation\n",
    "            loss.backward()\n",
    "            #gradient clipping\n",
    "            total_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            #update weights\n",
    "            optimizer.step()\n",
    "            #sum of loss per epoch\n",
    "            train_loss += loss.item() * sequences.size(0)  # accumulate total loss\n",
    "\n",
    "            #print('end of batch ' + str(i))\n",
    "        #average loss per epoch (divided by number of batches)\n",
    "        train_loss /= len(train_loader.dataset)  # divide by total samples\n",
    "        print(f\"[EPOCH {epoch + 1}] Training loss: {train_loss:.4f}\")\n",
    "\n",
    "        #Validation\n",
    "        print('validation')\n",
    "        print('validation loop, size of tensor: ' + str(len(val_loader)))\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        all_probs_val = []\n",
    "        all_labels_val = []\n",
    "        #only evaluation, no gradient updates\n",
    "        with torch.no_grad():\n",
    "            for i, (sequences, labels, magnitudes, task_labels) in enumerate(val_loader): #batch -> one evaluation per batch\n",
    "                sequences, labels, magnitudes, task_labels = sequences.to(device), labels.to(device), magnitudes.to(device), task_labels.to(device)\n",
    "                outputs = model(sequences)\n",
    "                probabilities = torch.sigmoid(outputs).squeeze()\n",
    "                loss = cross_entropy_loss(outputs, labels, class_weights=weight_tensor)\n",
    "                # sum of loss per epoch\n",
    "                val_loss += loss.item() * sequences.size(0)  # accumulate total loss\n",
    "                #append to list for storage\n",
    "                all_probs_val.append(probabilities.detach().cpu())\n",
    "                all_labels_val.append(labels.detach().cpu())\n",
    "\n",
    "        all_probs_val = torch.cat(all_probs_val).squeeze()\n",
    "        all_labels_val = torch.cat(all_labels_val).squeeze()\n",
    "        #On validation set, return the best threshold and performance to the Optuna\n",
    "        threshold, performance = threshold_tuning(all_probs_val, all_labels_val)\n",
    "        #print(all_probs_val)\n",
    "        print('threshold:' + str(threshold))\n",
    "        # average loss per epoch (divided by number of batches)\n",
    "        val_loss /= len(val_loader.dataset)  # divide by total samples\n",
    "        print(f\"[EPOCH {epoch + 1}] validation perf: {performance:.4f}\")\n",
    "        preds = (all_probs_val > threshold).int()\n",
    "        tpr, tnr, acc = evaluation(preds, all_labels_val)\n",
    "        #print(preds)\n",
    "        print(f\"[EPOCH {epoch + 1}] validation accuracy: {acc:.4f}\")\n",
    "        print(f\"[EPOCH {epoch + 1}] validation TPR:      {tpr:.4f}\")\n",
    "        print(f\"[EPOCH {epoch + 1}] validation TNR:  {tnr:.4f}\")\n",
    "        \n",
    "        epoch_end_time = time.time()\n",
    "        time_elapsed = epoch_end_time - epoch_start_time\n",
    "        print(f'Time elapsed for one epoch: {time_elapsed:.2f} sec')\n",
    "\n",
    "        # Scheduler & Early-stop\n",
    "        perf = tpr * tnr\n",
    "        scheduler.step(perf)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            print(f\"Current learning rate: {param_group['lr']}\")\n",
    "        #early stopping to prevent overfitting\n",
    "        if performance > best_perf:\n",
    "            best_perf = performance\n",
    "            no_improve_epochs = 0\n",
    "            best_model = model\n",
    "            best_epoch = epoch\n",
    "            best_tpr = tpr\n",
    "            best_tnr = tnr\n",
    "            best_acc =acc\n",
    "            best_threshold = threshold\n",
    "        else:\n",
    "            no_improve_epochs += 1\n",
    "        if no_improve_epochs >= tuning_params['patience']:\n",
    "            print('early stopping')\n",
    "            print('Best validation tpr x tnr: ' + str(best_perf))\n",
    "            print('Best validation tpr: ' + str(best_tpr))\n",
    "            print('Best validation tnr: ' + str(best_tnr))\n",
    "            print('Best validation acc: ' + str(best_acc))\n",
    "            break\n",
    "\n",
    "    #Persist best checkpoint\n",
    "    torch.save({\n",
    "       'epoch': best_epoch,\n",
    "        'model': best_model.state_dict() if best_model is not None else None,\n",
    "        'best_perf': best_perf,\n",
    "        'best_threshold': best_threshold,\n",
    "        'model_params': model_params,\n",
    "    }, f'{folder_name}/model_{trial.number}.pth')\n",
    "    return best_perf # value to be maximised by Optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769a0e32-09e8-4c0a-a8d7-c7ca22a57f3c",
   "metadata": {},
   "source": [
    "# Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7574d09e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Main training / HP tuning / testing script\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Data-set switches\n",
    "small_sample_size_experiment = False\n",
    "use_multiple_datesets = False\n",
    "use_perceptual_dataset = False\n",
    "use_neuromod_dataset = True\n",
    "\n",
    "#Apply CAR\n",
    "spatial_filter_use = True\n",
    "\n",
    "folder_name = 'Optuna_models_att'\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Channel subsets (feature selection)\n",
    "    RNN_features_PL_dataset = [4,8,10,14,18,20,24]\n",
    "    RNN_features_neuromod_dataset = np.linspace(0,31,32)\n",
    "    RNN_features_neuromod_dataset = RNN_features_neuromod_dataset.astype(int)\n",
    "    \n",
    "    number_of_features = len(RNN_features_neuromod_dataset)\n",
    "    \n",
    "    # Load whichever data set(s) are enabled\n",
    "    if use_perceptual_dataset is True:\n",
    "        rotation_dataset_all_subjects, labels_all_subjects, magnitudes_all_subjects = load_combined_data()\n",
    "        labels_all_subjects = np.squeeze(labels_all_subjects)\n",
    "        magnitudes_all_subjects = np.squeeze(magnitudes_all_subjects)\n",
    "        task_labels_all_subjects = np.ones(labels_all_subjects.size)\n",
    "        rotation_dataset_all_subjects = rotation_dataset_all_subjects[:,RNN_features_PL_dataset,:]\n",
    "        \n",
    "    if use_neuromod_dataset is True:\n",
    "        rotation_dataset_all_subjects, labels_all_subjects = load_neuromod_data()\n",
    "        labels_all_subjects = np.squeeze(labels_all_subjects)\n",
    "        task_labels_all_subjects = 2 * np.ones(labels_all_subjects.size) \n",
    "        task_labels_all_subjects = np.squeeze(task_labels_all_subjects)\n",
    "        magnitudes_all_subjects = np.ones(labels_all_subjects.size)\n",
    "        magnitudes_all_subjects = np.squeeze(magnitudes_all_subjects)\n",
    "        rotation_dataset_all_subjects = rotation_dataset_all_subjects[:,RNN_features_neuromod_dataset,:]\n",
    "        \n",
    "    if use_multiple_datesets is True:\n",
    "        rotation_dataset_all_subjects, labels_all_subjects, magnitudes_all_subjects = load_combined_data()\n",
    "        labels_all_subjects = np.squeeze(labels_all_subjects)\n",
    "        magnitudes_all_subjects = np.squeeze(magnitudes_all_subjects)\n",
    "        task_labels_PL = np.ones(labels_all_subjects.size)\n",
    "        rotation_dataset_all_subjects = rotation_dataset_all_subjects[:,RNN_features_PL_dataset,:]\n",
    "\n",
    "        \n",
    "        neuromod_dataset_all_subjects, neuromod_labels_all_subjects = load_neuromod_data()\n",
    "        task_labels_neuromod = 2 * np.ones(neuromod_labels_all_subjects.size)\n",
    "        neuromod_labels_all_subjects = np.squeeze(neuromod_labels_all_subjects)\n",
    "        labels_all_subjects = np.concatenate((labels_all_subjects, neuromod_labels_all_subjects))\n",
    "        magnitudes_temp = np.ones(neuromod_labels_all_subjects.size)\n",
    "        magnitudes_all_subjects = np.concatenate((magnitudes_all_subjects, magnitudes_temp))\n",
    "        task_labels_all_subjects = np.concatenate((task_labels_PL, task_labels_neuromod))\n",
    "        neuromod_dataset_all_subjects = neuromod_dataset_all_subjects[:,RNN_features_neuromod_dataset,:]\n",
    "        rotation_dataset_all_subjects = np.concatenate((rotation_dataset_all_subjects, neuromod_dataset_all_subjects))\n",
    "\n",
    "    \n",
    "    rotation_dataset_all_subjects = np.transpose(rotation_dataset_all_subjects, (2, 1, 0))\n",
    "\n",
    "    #shuffling across subjects and tasks:\n",
    "    shuffling_indexes = np.arange(labels_all_subjects.size)\n",
    "    np.random.shuffle(shuffling_indexes) \n",
    "    labels_all_subjects = labels_all_subjects[shuffling_indexes]\n",
    "    magnitudes_all_subjects = magnitudes_all_subjects[shuffling_indexes]\n",
    "    task_labels_all_subjects = task_labels_all_subjects[shuffling_indexes]\n",
    "    rotation_dataset_all_subjects = rotation_dataset_all_subjects[:,:,shuffling_indexes]\n",
    "\n",
    "\n",
    "    if small_sample_size_experiment is True:\n",
    "        rotation_dataset_all_subjects = rotation_dataset_all_subjects[:,:,:8000]\n",
    "        labels_all_subjects = labels_all_subjects[:8000]\n",
    "        magnitudes_all_subjects = magnitudes_all_subjects[:8000]\n",
    "        task_labels_all_subjects = task_labels_all_subjects[:8000]\n",
    "                \n",
    "\n",
    "    #Trial-level artefact rejection\n",
    "    cleaned_data, cleaned_labels, cleaned_magnitudes, cleaned_task_labels = sequence_rejection(rotation_dataset_all_subjects, labels_all_subjects, magnitudes_all_subjects, task_labels_all_subjects, 150)\n",
    "    cleaned_labels = cleaned_labels.reshape(-1, 1)\n",
    "    cleaned_magnitudes = cleaned_magnitudes.reshape(-1, 1)\n",
    "    cleaned_task_labels = cleaned_task_labels.reshape(-1, 1)\n",
    "    \n",
    "    print('number of trials after trial rejection ' + str(cleaned_data.shape))\n",
    "    print('number of labels after trial rejection ' + str(cleaned_labels.shape))\n",
    "\n",
    "    # Common Average Referencing\n",
    "    if spatial_filter_use is True:\n",
    "        cleaned_data = spatial_filter(cleaned_data)\n",
    "    \n",
    "    #Truncate to 1s period after trigger onset (note this depends on the dataset)\n",
    "    RNN_features = cleaned_data[256:, :, :]\n",
    "    print('Input space ' + str(RNN_features.shape))  # sequence length, features, number of sequences\n",
    "\n",
    "    # Dataset creation to integrate with PyTorch's DataLoader\n",
    "    RNN_features = np.transpose(RNN_features, (2, 0, 1)) # number of sequences, sequence length, features\n",
    "\n",
    "    tensor_data = ErrPDataset(RNN_features, cleaned_labels, cleaned_magnitudes, cleaned_task_labels)\n",
    "    # Sanity check on tensors\n",
    "    data = tensor_data[0]\n",
    "    print('Each sequence size ' + str(data['features'].shape))\n",
    "\n",
    "    # Dataset splitting\n",
    "    val_ratio = 0.1\n",
    "    test_ratio = 0.11\n",
    "    train_ratio = 1 - val_ratio - test_ratio\n",
    "    train_set, test_set, val_set = Dataset_splitting(tensor_data, train_ratio, val_ratio, test_ratio)\n",
    "    \n",
    "    #norm_train, norm_test, norm_val = data_normalization_v2(train_set, test_set, val_set)\n",
    "    norm_train, norm_test, norm_val = train_set, test_set, val_set\n",
    "    \n",
    "    print('train set size: ' + str(len(norm_train)))\n",
    "    print('test set size: ' + str(len(norm_test)))\n",
    "    print('val set size: ' + str(len(norm_val)))\n",
    "    \n",
    "    # Dataloaders\n",
    "    n_cpus = multiprocessing.cpu_count()\n",
    "    print('number of cpus ' + str(n_cpus))\n",
    "    n_workers = max(2, n_cpus // 2)\n",
    "    model_training_params = {'batch_size': 32}\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        norm_train,\n",
    "        batch_size=model_training_params['batch_size'],\n",
    "        # avoid shuffling for now\n",
    "        shuffle=True,\n",
    "        num_workers=n_workers,\n",
    "        pin_memory=True,\n",
    "        collate_fn=collate_fn,\n",
    "        drop_last=True\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        norm_val,\n",
    "        batch_size=model_training_params['batch_size'],\n",
    "        # avoid shuffling for now\n",
    "        shuffle=True,\n",
    "        num_workers=n_workers,\n",
    "        pin_memory=True,\n",
    "        collate_fn=collate_fn,\n",
    "        drop_last=True\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        norm_test,\n",
    "        batch_size=model_training_params['batch_size'],\n",
    "        # avoid shuffling for now\n",
    "        shuffle=True,\n",
    "        num_workers=n_workers,\n",
    "        pin_memory=True,\n",
    "        collate_fn=collate_fn,\n",
    "        drop_last=True\n",
    "    )\n",
    "\n",
    "    # Hyper-parameter search with Optuna \n",
    "    # If GPU is available, use a GPU\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print('number of GPUs ' + str(torch.cuda.device_count()))\n",
    "\n",
    "    sampler = RandomSampler(seed=40)\n",
    "    pruner = MedianPruner()\n",
    "    study = optuna.create_study(direction='maximize', sampler=sampler, pruner=pruner)\n",
    "    study.optimize(lambda trial: objective(trial, number_of_features, train_loader, val_loader, device, folder_name), n_trials=70)\n",
    "\n",
    "    def save_study(study, filename):\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(study, f)\n",
    "\n",
    "    save_study(study, f'{folder_name}.pkl')\n",
    "    print(f\"Best trial: {study.best_trial.number}\")\n",
    "\n",
    "    #Reload best checkpoint & evaluate on test\n",
    "    checkpoint = torch.load(f'{folder_name}/model_{study.best_trial.number}.pth', map_location=device)\n",
    "\n",
    "    model_params = checkpoint['model_params']\n",
    "    model = ErrPDetectionRNNModel_with_att(**model_params).to(device)\n",
    "    #model = ErrPDetectionRNNModel(**model_params).to(device)\n",
    "    model.load_state_dict(checkpoint['model'])  \n",
    "    best_threshold = checkpoint['best_threshold']\n",
    "    print(f\"[OPTUNA] Best threshold: {checkpoint['best_threshold']:.2f}\")\n",
    "    print(f\"[OPTUNA] Best validation performance: {checkpoint['best_perf']:.4f}\")\n",
    "    model.eval()\n",
    "\n",
    "    print(\"Running final evaluation on test set...\")\n",
    "\n",
    "    #Evaluation on the test set\n",
    "    all_predicted = []\n",
    "    all_labels = []\n",
    "    all_magnitudes = []\n",
    "    all_task_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (sequences, labels, magnitudes, task_labels) in enumerate(test_loader):  # batch -> one evaluation per batch\n",
    "            sequences, labels, magnitudes, task_labels = sequences.to(device), labels.to(device), magnitudes.to(device), task_labels.to(device)\n",
    "            outputs = model(sequences)\n",
    "            probabilities = torch.sigmoid(outputs)\n",
    "            all_predicted.append(probabilities)\n",
    "            all_labels.append(labels)\n",
    "            all_magnitudes.append(magnitudes)\n",
    "            all_task_labels.append(task_labels)\n",
    "\n",
    "    all_predicted = torch.cat(all_predicted).view(-1)\n",
    "    all_labels = torch.cat(all_labels).view(-1)\n",
    "    all_magnitudes = torch.cat(all_magnitudes).view(-1)\n",
    "    all_task_labels = torch.cat(all_task_labels).view(-1)\n",
    "    \n",
    "    preds = (all_predicted > best_threshold).int()\n",
    "    tpr, tnr, acc = evaluation(preds, all_labels)\n",
    "    print(f\"Accuracy:  {acc:.4f}\")\n",
    "    print(f\"TPR:       {tpr:.4f}\")\n",
    "    print(f\"TNR:       {tnr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c84a38-997e-422f-aa04-39d4a6625c31",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c75bcb1-6683-4e87-8424-547b3a091804",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(study.best_trial.number)\n",
    "best_threshold = 0.03\n",
    "preds = (all_predicted > best_threshold).int()\n",
    "tpr, tnr, acc = evaluation(preds[all_task_labels==1], all_labels[all_task_labels==1])\n",
    "print(f\"Task 1 Accuracy:  {acc:.4f}\")\n",
    "print(f\"Task 1 TPR:       {tpr:.4f}\")\n",
    "print(f\"Task 1 TNR:       {tnr:.4f}\")\n",
    "\n",
    "tpr, tnr, acc = evaluation(preds[(all_task_labels==1) & (all_magnitudes==6)], all_labels[(all_task_labels==1) & (all_magnitudes==6)])\n",
    "print(f\"Task 1 3 mag Accuracy:  {acc:.4f}\")\n",
    "print(f\"Task 1 3 mag TPR:       {tpr:.4f}\")\n",
    "print(f\"Task 1 3 mag TNR:       {tnr:.4f}\")\n",
    "\n",
    "tpr, tnr, acc = evaluation(preds[(all_task_labels==1) & (all_magnitudes==0)], all_labels[(all_task_labels==1) & (all_magnitudes==0)])\n",
    "print(f\"Task 1 0 mag Accuracy:  {acc:.4f}\")\n",
    "print(f\"Task 1 0 mag TPR:       {tpr:.4f}\")\n",
    "print(f\"Task 1 0 mag TNR:       {tnr:.4f}\")\n",
    "\n",
    "tpr, tnr, acc = evaluation(preds[all_task_labels==2], all_labels[all_task_labels==2])\n",
    "print(f\"Task 2 Accuracy:  {acc:.4f}\")\n",
    "print(f\"Task 2 TPR:       {tpr:.4f}\")\n",
    "print(f\"Task 2 TNR:       {tnr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bd8566-3b3f-4151-8ae2-157525e42dfe",
   "metadata": {},
   "source": [
    "# Some sanity checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc157e5-4fcd-412f-b229-2e94da264313",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "small_sample_size_experiment = False\n",
    "#note large input dataset leads to crashing\n",
    "use_multiple_datesets = False\n",
    "use_perceptual_dataset = True \n",
    "use_neuromod_dataset = False \n",
    "shuffling = False\n",
    "\n",
    "\n",
    "# Features extraction\n",
    "RNN_features_PL_dataset = [4,8,10,14,18,20,24]\n",
    "RNN_features_neuromod_dataset = [5,9,10,15,20,21,25]\n",
    "\n",
    "if use_perceptual_dataset:\n",
    "    rotation_dataset_all_subjects, labels_all_subjects, magnitudes_all_subjects = load_combined_data()\n",
    "    labels_all_subjects = np.squeeze(labels_all_subjects)\n",
    "    magnitudes_all_subjects = np.squeeze(magnitudes_all_subjects)\n",
    "    task_labels_PL = np.ones(labels_all_subjects.size)\n",
    "\n",
    "if use_neuromod_dataset: \n",
    "    rotation_dataset_all_subjects, labels_all_subjects = load_neuromod_data()\n",
    "    labels_all_subjects = np.squeeze(labels_all_subjects)\n",
    "\n",
    "    \n",
    "if use_multiple_datesets is True:    \n",
    "    labels_all_subjects = np.concatenate((labels_all_subjects, neuromod_labels_all_subjects))\n",
    "    magnitudes_all_subjects = np.concatenate((magnitudes_all_subjects, magnitudes_temp))\n",
    "    \n",
    "    task_labels_all_subjects = np.concatenate((task_labels_PL, task_labels_neuromod))\n",
    "    neuromod_dataset_all_subjects = neuromod_dataset_all_subjects[:,RNN_features_neuromod_dataset,:]\n",
    "    rotation_dataset_all_subjects = np.concatenate((rotation_dataset_all_subjects, neuromod_dataset_all_subjects))\n",
    "    \n",
    "    \n",
    "rotation_dataset_all_subjects = rotation_dataset_all_subjects[:,RNN_features_PL_dataset,:]\n",
    "number_of_features = len(RNN_features_PL_dataset)\n",
    "\n",
    "\n",
    "#GA plotting\n",
    "#GA_plotting(first_subject_data, first_subject_labels, 15)\n",
    "rotation_dataset_all_subjects = np.transpose(rotation_dataset_all_subjects, (2, 1, 0))\n",
    "\n",
    "#shuffling across subjects and tasks:\n",
    "if shuffling is True:\n",
    "    shuffling_indexes = np.arange(labels_all_subjects.size)\n",
    "    np.random.shuffle(shuffling_indexes) \n",
    "    labels_all_subjects = labels_all_subjects[shuffling_indexes]\n",
    "    magnitudes_all_subjects = magnitudes_all_subjects[shuffling_indexes]\n",
    "    task_labels_all_subjects = task_labels_all_subjects[shuffling_indexes]\n",
    "    rotation_dataset_all_subjects = rotation_dataset_all_subjects[:,:,shuffling_indexes]\n",
    "\n",
    "\n",
    "if small_sample_size_experiment is True:\n",
    "    rotation_dataset_all_subjects = rotation_dataset_all_subjects[:,:,:1000]\n",
    "    labels_all_subjects = labels_all_subjects[:1000]\n",
    "    magnitudes_all_subjects = magnitudes_all_subjects[:1000]\n",
    "    task_labels_all_subjects = task_labels_all_subjects[:1000]\n",
    "\n",
    "print(rotation_dataset_all_subjects.shape)\n",
    "\n",
    "logical_index = ~np.any(np.abs(rotation_dataset_all_subjects) > 100, axis=(0, 1))\n",
    "logical_index = logical_index & (magnitudes_all_subjects == 12)\n",
    "rotation_dataset_all_subjects = rotation_dataset_all_subjects[:,:,logical_index]\n",
    "labels_all_subjects = labels_all_subjects[logical_index]\n",
    "\n",
    "error_mean, correct_mean = GA_plotting(rotation_dataset_all_subjects, labels_all_subjects, 0)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "RNN_ErrP_Deland",
   "language": "python",
   "name": "rnn_errp_deland"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
